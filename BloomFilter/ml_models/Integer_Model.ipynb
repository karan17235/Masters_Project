{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# import numpy as np\n",
    "\n",
    "# data = pd.read_csv(\"../data/random.csv\", header=None) \n",
    "# keys = data[0]\n",
    "# np.random.shuffle(keys)\n",
    "# positive_keys = keys * 0.5\n",
    "# data_fraction = 0.5\n",
    "# positives = keys[:int(data_fraction * len(keys))]\n",
    "# negatives = keys[int(data_fraction * len(keys)) : int(len(keys))]\n",
    "# positives = set(positives)\n",
    "# negatives = set(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shuffling the data\n",
    "# a = [(i, 1) for i in positives]\n",
    "# b = [(i, 0) for i in negatives]\n",
    "# combined = a + b\n",
    "# np.random.shuffle(combined)\n",
    "# shuffled = list(zip(*combined))\n",
    "# data = shuffled[0]\n",
    "# labels = shuffled[1]\n",
    "\n",
    "# data = np.asarray(data)\n",
    "# data = data.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import model_selection, preprocessing\n",
    "# X_train, X_test, y_train, y_test = model_selection.train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[100001, 100002, 100003, 100004, 100005, 100006, 100007, 100008, 100009, 100010]\n",
      "108998\n",
      "108998\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "M = 100000\n",
    "N = 9000\n",
    "present = [i for i in range(1, M)]\n",
    "absent = [i for i in range(M+1,N+M)] \n",
    "print(present[:10])\n",
    "print(absent[:10])\n",
    "# Shuffling the data\n",
    "a = [(i, 1) for i in present]\n",
    "b = [(i, 0) for i in absent]\n",
    "combined = a + b\n",
    "np.random.shuffle(combined)\n",
    "shuffled = list(zip(*combined))\n",
    "data = shuffled[0]\n",
    "print(len(data))\n",
    "labels = shuffled[1]\n",
    "print(len(labels))\n",
    "data = np.asarray(data)\n",
    "data = data.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = preprocessing.StandardScaler().fit(data)\n",
    "# data = scaler.transform(data)\n",
    "# print(data[:10])\n",
    "from sklearn import model_selection, preprocessing\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(data, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  0:00:00.087329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/research_data/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import datetime\n",
    "\n",
    "train_start = datetime.datetime.now()\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "train_end = datetime.datetime.now()\n",
    "print(\"Training time: \", (train_end - train_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.92\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# present = np.asarray(present)\n",
    "# present = present.reshape(-1, 1)\n",
    "# scaler = preprocessing.StandardScaler().fit(present)\n",
    "# positive = scaler.transform(present)\n",
    "# pred_positive = logreg.predict(present)\n",
    "\n",
    "# false_positive = 0\n",
    "# if pred_positive > 0.5:\n",
    "#     print(\"False negative\")\n",
    "    \n",
    "# for pred in pred_positive:\n",
    "#     if i < 0.5:\n",
    "#         false_positive += 1\n",
    "# print(false_positive)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0  1796]\n",
      " [    0 20004]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network for Integer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(200, input_dim = 1))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Dense(200))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = 2048, epochs = 40, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
